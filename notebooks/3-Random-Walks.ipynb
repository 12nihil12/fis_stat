{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multidimensional arrays\n",
    "import numpy as np\n",
    "\n",
    "# inline plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# nicer figures\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return to the origin\n",
    "\n",
    "\n",
    "For a *finite* random walk of (large) length $n$, it is known that the expected number of returns to the origin $T_n$ scales like follows:\n",
    "$$\n",
    "\\left\\langle T_n \\right\\rangle \\sim \\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\sqrt{n} & d=1 \\\\\n",
    "\\log(n) & d=2 \\\\\n",
    "C_d & d\\geq 3\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "<img src=\"attachment:image.png\" width=\"600\">\n",
    "\n",
    "Notice that for $d \\geq 3$, $\\left\\langle T_n \\right\\rangle$ does **not** grow with $n$, which must mean that the walker somehow \"escapes\" and never returns back to the origin. The probability of return to the origin is less than 1! For an infinite-length random walk, indeed the probability of returning to the origin $\\rho$ is seen to be\n",
    "\n",
    "$$\n",
    "\\rho \\sim \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & d=1 \\\\\n",
    "1 & d=2 \\\\\n",
    "<1 & d\\geq 3\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "The *intuitive* explanation of this amazing fact is that, as the dimension $d$ grows, there are \"more directions available\", and so more chances for the walker to \"get lost\" and never return to the origin. There is of course a formal proof as well, but today we will do a **computational verification** of these facts, which is no substitute for a formal proof but is often all we can do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Random Walks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "Write a function that generates a random walk of given length in $d$ dimensions. Your random walker should move as follows:\n",
    "\n",
    "+ At each time-step, the walker moves only in one direction.\n",
    "+ At each time-step, the walker moves only by -1 or +1\n",
    "\n",
    "Your function should return a numpy array of shape (`length`, `dim`). Example:\n",
    "```python\n",
    ">>> # create a RW of length 10 in dimension 3\n",
    ">>> traj = get_traj(length=10, dim=3)\n",
    ">>> # check that the output has the right shape\n",
    ">>> traj.shape\n",
    "(10, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def get_traj(length=100, dim=2):\n",
    "    \"\"\"Generate a RW in d dimensions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    length: int\n",
    "        Length of the RW.\n",
    "    dim: int\n",
    "        Dimension of the RW\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    traj : np.ndarray, (length, dim)\n",
    "        The positions of the RW.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    At each time-step, the walker moves in only one direction.\n",
    "    At each time-step, the walker moves by -1 or +1\n",
    "    \"\"\"\n",
    "    traj=np.zeros([length,dim])\n",
    "\n",
    "  \n",
    "    for i in range(1, traj.shape[0]):\n",
    "        col=random.randint(0,dim-1)\n",
    "        traj[i,col]= random.choice([1,-1])\n",
    "        traj[i,:]=traj[i,:]+traj[i-1,:]\n",
    "\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "To make sure that your function works correctly, execute the following cell. Notice the use of `assert` statements: execution should fail if something goes wrong. If everything is fine, nothing should happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic checks for your RW generator\n",
    "for dim in range(1, 5):\n",
    "    for length in [10, 100, 200, 500]:\n",
    "        traj = get_traj(length=length, dim=dim)\n",
    "        # make sure traj has the right shape\n",
    "        assert traj.shape == (length, dim)\n",
    "        # make sure all steps are -1 or 1 in only one direction\n",
    "        assert np.all(np.sum(np.diff(traj, axis=0) != 0, axis=1) == np.ones(length - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2\n",
    "Plot a random walk of length $10^4$ for $d=1$ (time in x-axis, position in y-axis) and $d=2$ (x,y components in x,y-axis). Remember to use **axis labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is better if you use one cell to generate the random walks, and a second cell to plot them\n",
    "RW_1d = ...\n",
    "RW_2d = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a figure with two subplots, called axis in matplotlib.\n",
    "#\n",
    "# To use the left subplot, we do\n",
    "# ax1.plot(...)\n",
    "#\n",
    "# while to use the right subplot, we do\n",
    "# ax2.plot(..)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting the number of returns to the origin\n",
    "Since we are interested in how **the expected number of returns to the origin** scales with the RW length, we don't need to store the whole trajectory of each simulation (we will be performing many simulations!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "Write a function that generates a RW of given length and dimension (calling `get_traj`), and returns the number of times it returned to the origin. To count the number of returns to the origin, you might need to use the following functions:\n",
    "```python\n",
    "np.all()\n",
    "np.zeros()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_returns(length, dim):\n",
    "    # generate a RW of given length and dimension\n",
    "    traj = ...\n",
    "    # count how many times it goes through the origin\n",
    "    ...\n",
    "    ...\n",
    "    return num_returns_to_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4\n",
    "Write a function that computes the expected number of returns to the origin for a given length and dimension. Your function will call `get_num_returns()`, and should have an additional parameter that sets the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_num_returns(length, dim, num_trajs=200):\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    return average_num_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with analytical results\n",
    "We are now ready to compare our analytical results with numerical simulations! We want to plot the expected number of returns to the origin as a function of the RW length. To do this, it is useful to first define an array of RW lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of RW lengths\n",
    "length_min = 10\n",
    "length_max = 100000\n",
    "# generate points logarithmically spaces\n",
    "# and convert them to integers\n",
    "length_array = np.array([\n",
    "    int(x)\n",
    "    for x in np.geomspace(length_min, length_max, num=20)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tip: if your RW generating function is not very efficient, you might want to decrease `length_min`)  \n",
    "\n",
    "Executing the following cell will run all simulations for $d=1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=1\n",
    "num_returns_array = np.array([\n",
    "    get_average_num_returns(length=length, dim=dim)\n",
    "    for length in length_array\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.5\n",
    "Plot the average number of returns to the origin of a 1D RW as a function of the RW length, together with the expected theoretical result. Do your results verify the $n^{1/2}$ scaling? **Tip** Use double-logarithmic scales in your plot. Remember to include label axis, and a legend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "# plot theoretical result\n",
    "ax.loglog(..., label=\"Theory\")\n",
    "# plot numerical result\n",
    "ax.loglog(..., label=\"Numerics\")\n",
    "# add axis labels\n",
    "...\n",
    "...\n",
    "# add a legend\n",
    "...\n",
    "# add a title (e.g. that says what dimension we used)\n",
    "ax.set_title(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.6\n",
    "Plot the average number of returns to the origin of a 2D RW as a function of the RW length. Do your results verify the $log(n)$ scaling? What are the best axis scales to use in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the simulations for d=2\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the numerical results + theory\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.7\n",
    "Show numerically that, for $d=3$ and $d=4$, the expected number of returns to the origin is **constant**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your numerical answer here\n",
    "# you can use more than one cell of course!\n",
    "# use markdown cells and code cells if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Avoiding Walks\n",
    "Self-avoiding walks (SAW) are simply random walks in a regular lattice with the additional constraint that no point can be visited more than once. That is, SAWs cannot intersect themselves. The most well-known application of SAW is to model linear polymers, where obviously two monomers cannot occupy the same space (excluded volume effect).\n",
    "\n",
    "\n",
    "You can read more about self-avoiding walks in this nice introduction by Gordon Slade:\n",
    "\n",
    "[Self-Avoiding Walks, by Gordon Slade](https://www.math.ubc.ca/~slade/intelligencer.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Self-Avoiding Walks\n",
    "Generating a SAW is not trivial. If you try to generate a SAW stochastically, that is, one step at a time, you will miserably fail: your walker might get into traps (configurations with no allowed movements), and if it does you will have to discard your simulation. It turns out you will have to discard your simulation *really* often, so that for large lengths, you will basically never find a valid path. In addition, the paths you will find for short lengths will not come up with the right probabilities. Bear in mind that we want to **uniformly sample** the set of SAW of given length $n$, SAW($n$). That is, we want that all paths from SAW($n$) are generated with the same probability.\n",
    "\n",
    "The solution is to use a Monte Carlo algorithm that, given one element $\\alpha \\in \\text{SAW}(n)$, generates a new one $\\beta \\in \\text{SAW}(n)$ with some probability $P_{\\alpha \\beta}$. If in addition our algorithm satisfies **detailed balance** and is **ergodic**, then we known that it will converge to the equilibrium distribution (the uniform distribution in our case).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pivot algorithm\n",
    "We will implement the pivot algorithm, which is simple, effective, and satisfies detailed balance and ergodicity. You can read about the details of the pivot algorithm here:\n",
    "\n",
    "[The Pivot Algorithm: A Highly Efficient Monte Carlo Method for the Self-Avoiding Walk](https://link.springer.com/article/10.1007/BF01022990)\n",
    "\n",
    "(tip: if you're at home, **do not** use tools such as sci-hub to download the paper).\n",
    "\n",
    "Given a self-avoiding walk of length $n$, the pivot algorithm generates the next walk $\\beta \\in \\text{SAW}(n)$ as follows:\n",
    "\n",
    "1. **Choose a point of $\\alpha$ at random**, splitting the path in two bits: the head (from the origin to the chosen point) and the tail (from the chosen point to the end of the path). Notice that both the head and the tail are SAWs.\n",
    "2. **Apply a transformation to the tail**, leaving the head intact. The transformation must be an orthoganl transformation that leaves the regular lattice intact (so, either a reflection or a $90º, 180º$ or $270º$ rotation). For simplicity, we will use only **rotations** (read the paper to see why this is ok).\n",
    "3. **Check if the new path is self-avoiding**. If so, return it. Otherwise, return the original path.\n",
    "\n",
    "Iterating these steps one obtains a **Markov** chain of SAWs: $\\alpha_1 \\to \\alpha_2 \\to \\dots \\to \\alpha_M $. Notice that $\\alpha_i$ are not uncorrelated, but because the algorithm satisfies detailed balance and is ergodic, we know that it approaches the equilibrium distribution. This means that we can use our Markov chain to compute **expected values** as long as it is long enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the pivot step in 2D\n",
    "To implement the **pivot algorithm** in 2D, we will write one function that does steps 1 and 2, and another function that does step 3. We will also need a function to generate standard 2D random walks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.8\n",
    "Write a function `get_traj` that generates a 2D random walk of given length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traj(length):\n",
    "    \"\"\"Generate a 2D random walk of given length\"\"\"\n",
    "    ...\n",
    "    ...\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.9\n",
    "Write a function `pivot_traj` that, given a 2D random walk, performs steps 1 and 2 of the pivot algorithm. Some useful functions:\n",
    "```python\n",
    "np.random.randint()\n",
    "np.concatenate()\n",
    "```\n",
    "You might also want to multiply matrices using the `@` operator:\n",
    "```python\n",
    ">>> a = np.array([[1, 2], [3, 4], [5, 6]])\n",
    ">>> b = np.array([1, 1])\n",
    ">>> a @ b\n",
    "array([ 3,  7, 11])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_traj(traj):\n",
    "    \"\"\"Apply a random rotation to part of a RW.\"\"\"\n",
    "    \n",
    "    # choose the pivot\n",
    "    pivot_index = ...\n",
    "    pivot_point = traj[pivot_index]\n",
    "\n",
    "    # split head and tail\n",
    "    traj_head = ...\n",
    "    traj_tail = ...\n",
    "    \n",
    "    # define the rotation matrices\n",
    "    symmetries = [\n",
    "        # 90 deg rotation\n",
    "        np.array([[ , ], [ , ]]),\n",
    "        # 180 deg rotation\n",
    "        np.array([[ , ], [ , ]]),\n",
    "        # 270 deg rotation\n",
    "        np.array([[ , ], [ , ]]),\n",
    "    ]\n",
    "    \n",
    "    # choose one rotation at random\n",
    "    symmetry = symmetries[...]\n",
    "\n",
    "    # apply the transformation to the tail\n",
    "    new_tail = ...\n",
    "    \n",
    "    # join the old head with the new tail\n",
    "    new_traj = ...\n",
    "    \n",
    "    return new_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.10\n",
    "Write a function that counts the number of self-intersections of a RW. Notice that SAWs have 0 self intersections, so that will solve step 3 of the pivot algorithm, but will also be useful to generate the initial condition. One way of approaching this exercise is to count how many *different* points the path visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_self_intersections(traj):\n",
    "    \"\"\"Count the number of self-intersections of a RW\"\"\"\n",
    "    ...\n",
    "    ...\n",
    "    return num_self_intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.11\n",
    "Verify that your `count_self_intersecitons` function works properly by using short trajectories for which you know the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your verifications here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the initial condition\n",
    "You might have noticed that the pivot algorithm requires an element of SAW($n$) as starting condition, to then generate a Markov chain easily. But how do you get this first element? We will use the following strategy:\n",
    "1. Generate a standard 2D random walk, and count the number of self intersections.\n",
    "2. Apply the pivot transformation to get a new 2D random walk, and count the number of self-intersections-\n",
    "3. If the number of self-intersections has decreased or not changed, keep the new path. Else, keep the old one.\n",
    "4. Go to 2, till the number of self-intersections is 0.\n",
    "\n",
    "### Exercise 3.12\n",
    "Write a function `get_first_SAW` that generates a SAW of given length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_SAW(length, max_tries=1000000):\n",
    "    ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.13\n",
    "Generate and plot some 2D SAWs of different lengths. Be carefull, raise the length slowly! You can measure how long a cell takes executing using the `%%time` magic at the top of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "# use more than one cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.14\n",
    "Write a function `get_next_SAW` that, given a SAW, generates another SAW using the pivot algorithm. Your function should check that the input RW is really a SAW. Remember the steps:\n",
    "\n",
    "1. Apply the pivot transformation\n",
    "2. Check if the new path is self-avoiding. **If so, return it. Otherwise, return the original path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_SAW(traj):\n",
    "    # make sure input traj is SAW\n",
    "    assert ...\n",
    "    \n",
    "    # pivot step\n",
    "    proposed_traj = ...\n",
    "    \n",
    "    # count intersections\n",
    "    num_intersections = count_self_intersections(proposed_traj)\n",
    "    \n",
    "    # if it's a SAW\n",
    "    if ...:\n",
    "        ...\n",
    "    \n",
    "    # if not\n",
    "    else:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Displacement in SAW\n",
    "A quantity of interest in RWs is the mean squared displacement, which is simply the (squared) distance between the endpoints of the walk. Usually, one writes\n",
    "\n",
    "$$\n",
    "\\left\\langle X(n)^2 \\right\\rangle \\sim n^{2 \\nu}\n",
    "$$\n",
    "\n",
    "As you know, for a standard RW of $n$ steps, the mean-squared displacement scales like $n$, so $\\nu=1/2$. However, the exponent for SAW is **different**! Althought it has not been formally proven (still), it is believed that the exponent for SAW is $\\nu=3/4$. That is, for a self-avoiding random walk, the mean squared displacement scales as $n^{3/2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.15\n",
    "Explain why it makes sense that the mean-squared displacement exponent of SAW is **greater** than that of standard RW. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here! (cannot be empty...)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.16\n",
    "Verify numerically the scaling of the mean-squared displacement of SAW. Notice that you don't need to store all the SAWs, just the endpoints. You could follow this scheme:\n",
    "\n",
    "1. Generate a first SAW with your `get_first_SAW()` function\n",
    "2. Generate the next SAW using your `get_next_SAW()` function, and store the endpoint.\n",
    "3. Iterate step 2 for as many steps as required\n",
    "4. Compute the average mean-squared displacement of the stored endpoints\n",
    "\n",
    "Then repeating steps 1-4 for different lengths, and plot the results in double-logarithmic axis. Compare your results with the theoretical exponent. Do they agree?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
